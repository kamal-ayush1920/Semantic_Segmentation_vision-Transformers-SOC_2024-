{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0405965d-6273-4f1f-9c87-fd1dea7adeca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.transforms import functional as F\n",
    "from torchvision.datasets import VOCSegmentation\n",
    "\n",
    "# Define transformations\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "val_transform = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "# Load dataset\n",
    "train_dataset = VOCSegmentation(root='.', year='2012', image_set='train', download=True, transform=train_transform)\n",
    "val_dataset = VOCSegmentation(root='.', year='2012', image_set='val', download=True, transform=val_transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=4, shuffle=True, num_workers=4)\n",
    "val_loader = DataLoader(val_dataset, batch_size=4, shuffle=False, num_workers=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e846db83-206f-4d7f-9933-1359d2f5a0d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class ConvBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(ConvBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = F.relu(x)\n",
    "        return x\n",
    "\n",
    "class AttentionBlock(nn.Module):\n",
    "    def __init__(self, F_g, F_l, F_int):\n",
    "        super(AttentionBlock, self).__init__()\n",
    "        self.W_g = nn.Sequential(\n",
    "            nn.Conv2d(F_g, F_int, kernel_size=1, stride=1, padding=0, bias=True),\n",
    "            nn.BatchNorm2d(F_int)\n",
    "        )\n",
    "\n",
    "        self.W_x = nn.Sequential(\n",
    "            nn.Conv2d(F_l, F_int, kernel_size=1, stride=1, padding=0, bias=True),\n",
    "            nn.BatchNorm2d(F_int)\n",
    "        )\n",
    "\n",
    "        self.psi = nn.Sequential(\n",
    "            nn.Conv2d(F_int, 1, kernel_size=1, stride=1, padding=0, bias=True),\n",
    "            nn.BatchNorm2d(1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "\n",
    "    def forward(self, g, x):\n",
    "        g1 = self.W_g(g)\n",
    "        x1 = self.W_x(x)\n",
    "        psi = self.relu(g1 + x1)\n",
    "        psi = self.psi(psi)\n",
    "        return x * psi\n",
    "\n",
    "class UpConv(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(UpConv, self).__init__()\n",
    "        self.up = nn.Sequential(\n",
    "            nn.ConvTranspose2d(in_channels, out_channels, kernel_size=2, stride=2),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.up(x)\n",
    "\n",
    "class AttentionUNet(nn.Module):\n",
    "    def __init__(self, img_ch=3, output_ch=21):  # VOC dataset has 21 classes\n",
    "        super(AttentionUNet, self).__init__()\n",
    "\n",
    "        self.Maxpool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        self.Conv1 = ConvBlock(img_ch, 64)\n",
    "        self.Conv2 = ConvBlock(64, 128)\n",
    "        self.Conv3 = ConvBlock(128, 256)\n",
    "        self.Conv4 = ConvBlock(256, 512)\n",
    "        self.Conv5 = ConvBlock(512, 1024)\n",
    "\n",
    "        self.Up5 = UpConv(1024, 512)\n",
    "        self.Att5 = AttentionBlock(F_g=512, F_l=512, F_int=256)\n",
    "        self.Up_conv5 = ConvBlock(1024, 512)\n",
    "\n",
    "        self.Up4 = UpConv(512, 256)\n",
    "        self.Att4 = AttentionBlock(F_g=256, F_l=256, F_int=128)\n",
    "        self.Up_conv4 = ConvBlock(512, 256)\n",
    "\n",
    "        self.Up3 = UpConv(256, 128)\n",
    "        self.Att3 = AttentionBlock(F_g=128, F_l=128, F_int=64)\n",
    "        self.Up_conv3 = ConvBlock(256, 128)\n",
    "\n",
    "        self.Up2 = UpConv(128, 64)\n",
    "        self.Att2 = AttentionBlock(F_g=64, F_l=64, F_int=32)\n",
    "        self.Up_conv2 = ConvBlock(128, 64)\n",
    "\n",
    "        self.Conv_1x1 = nn.Conv2d(64, output_ch, kernel_size=1, stride=1, padding=0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Encoding path\n",
    "        x1 = self.Conv1(x)\n",
    "\n",
    "        x2 = self.Maxpool(x1)\n",
    "        x2 = self.Conv2(x2)\n",
    "\n",
    "        x3 = self.Maxpool(x2)\n",
    "        x3 = self.Conv3(x3)\n",
    "\n",
    "        x4 = self.Maxpool(x3)\n",
    "        x4 = self.Conv4(x4)\n",
    "\n",
    "        x5 = self.Maxpool(x4)\n",
    "        x5 = self.Conv5(x5)\n",
    "\n",
    "        # Decoding + Concatenation path\n",
    "        d5 = self.Up5(x5)\n",
    "        x4 = self.Att5(g=d5, x=x4)\n",
    "        d5 = torch.cat((x4, d5), dim=1)\n",
    "        d5 = self.Up_conv5(d5)\n",
    "\n",
    "        d4 = self.Up4(d5)\n",
    "        x3 = self.Att4(g=d4, x=x3)\n",
    "        d4 = torch.cat((x3, d4), dim=1)\n",
    "        d4 = self.Up_conv4(d4)\n",
    "\n",
    "        d3 = self.Up3(d4)\n",
    "        x2 = self.Att3(g=d3, x=x2)\n",
    "        d3 = torch.cat((x2, d3), dim=1)\n",
    "        d3 = self.Up_conv3(d3)\n",
    "\n",
    "        d2 = self.Up2(d3)\n",
    "        x1 = self.Att2(g=d2, x=x1)\n",
    "        d2 = torch.cat((x1, d2), dim=1)\n",
    "        d2 = self.Up_conv2(d2)\n",
    "\n",
    "        out = self.Conv_1x1(d2)\n",
    "\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "230f75e3-b4b5-4468-b143-0de771f6c8e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "from torchvision.utils import save_image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
    "\n",
    "def train(model, train_loader, criterion, optimizer, device):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(train_loader):\n",
    "        inputs, labels = data\n",
    "        inputs, labels = inputs.to(device), labels['segmentation'].to(device).long()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels.squeeze(1))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    epoch_loss = running_loss / len(train_loader)\n",
    "    print(f'Training Loss: {epoch_loss:.4f}')\n",
    "    return epoch_loss\n",
    "\n",
    "def evaluate(model, val_loader, criterion, device):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for i, data in enumerate(val_loader):\n",
    "            inputs, labels = data\n",
    "            inputs, labels = inputs.to(device), labels['segmentation'].to(device).long()\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels.squeeze(1))\n",
    "\n",
    "            running_loss += loss.item()\n",
    "\n",
    "    epoch_loss = running_loss / len(val_loader)\n",
    "    print(f'Validation Loss: {epoch_loss:.4f}')\n",
    "    return epoch_loss\n",
    "\n",
    "# Training loop\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = AttentionUNet(img_ch=3, output_ch=21).to(device)\n",
    "\n",
    "num_epochs = 25\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    print(f'Epoch {epoch+1}/{num_epochs}')\n",
    "    train_loss = train(model, train_loader, criterion, optimizer, device)\n",
    "    val_loss = evaluate(model, val_loader, criterion, device)\n",
    "    train_losses.append(train_loss)\n",
    "    val_losses.append(val_loss)\n",
    "\n",
    "# Save the model\n",
    "torch.save(model.state_dict(), 'attention_unet.pth')\n",
    "\n",
    "# Plot loss curves\n",
    "plt.figure()\n",
    "plt.plot(train_losses, label='Train Loss')\n",
    "plt.plot(val_losses, label='Validation Loss')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df0c6418-b7bd-4ff0-b7d8-5d5463ea08ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_sample(model, val_loader, device):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for i, data in enumerate(val_loader):\n",
    "            inputs, labels = data\n",
    "            inputs, labels = inputs.to(device), labels['segmentation'].to(device).long()\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "\n",
    "            plt.figure(figsize=(10, 5))\n",
    "            plt.subplot(1, 3, 1)\n",
    "            plt.imshow(inputs.cpu().squeeze().permute(1, 2, 0).numpy())\n",
    "            plt.title('Input Image')\n",
    "            \n",
    "            plt.subplot(1, 3, 2)\n",
    "            plt.imshow(labels.cpu().squeeze().numpy())\n",
    "            plt.title('Ground Truth')\n",
    "\n",
    "            plt.subplot(1, 3, 3)\n",
    "            plt.imshow(preds.cpu().squeeze().numpy())\n",
    "            plt.title('Predicted Segmentation')\n",
    "\n",
    "            plt.show()\n",
    "\n",
    "            if i == 2:  # Display a few samples\n",
    "                break\n",
    "\n",
    "# Visualize some predictions\n",
    "visualize_sample(model, val_loader, device)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
